{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab_wsb.ipynb","provenance":[],"authorship_tag":"ABX9TyPFZbTxdX9BDNZiowCqncJN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ba1d7dfc4526444b8dd9b528bbd72ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33ace3c171d649268e07e51e000213c0","IPY_MODEL_47b802f304e0422ca87ed99774c14bc9","IPY_MODEL_494786c15e714fb890c529a251ab49f6"],"layout":"IPY_MODEL_25d7a43716014360b4d7136b2bc179bb"}},"33ace3c171d649268e07e51e000213c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8834dfcf6c134a1989be21a3fbb06d95","placeholder":"​","style":"IPY_MODEL_97b6e8f2b84343c69b7baf1d7f2aa7e9","value":"Finding best initial lr: 100%"}},"47b802f304e0422ca87ed99774c14bc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5078b1184c44babea57188016651c7","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a448c5c29ae24583b07be9d1abc4170c","value":100}},"494786c15e714fb890c529a251ab49f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30cf8fbff230435d99737abe196b7ca5","placeholder":"​","style":"IPY_MODEL_72696459bf9d4ee9a95b734bf0a170ff","value":" 100/100 [01:57&lt;00:00,  2.81it/s]"}},"25d7a43716014360b4d7136b2bc179bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8834dfcf6c134a1989be21a3fbb06d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97b6e8f2b84343c69b7baf1d7f2aa7e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c5078b1184c44babea57188016651c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a448c5c29ae24583b07be9d1abc4170c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30cf8fbff230435d99737abe196b7ca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72696459bf9d4ee9a95b734bf0a170ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fcf19686218495dbcf90457e0dd6818":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afd531712de6430e8eb4a8e0a2c73a7c","IPY_MODEL_9dd123c3490d4dd290cbb3552dd69d28","IPY_MODEL_a5d0a7c1c76a40448c74fa363351aee4"],"layout":"IPY_MODEL_c131155f97b14a73b35dd538b717f548"}},"afd531712de6430e8eb4a8e0a2c73a7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0e01b6b61894023961db665943f2099","placeholder":"​","style":"IPY_MODEL_04aba4e93de7481798a77ec61bac428f","value":"Sanity Checking DataLoader 0: 100%"}},"9dd123c3490d4dd290cbb3552dd69d28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9e5e552a396463b9a8e6b576b2273fc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df6ef02c4ae245bf9a8599b7b329f11e","value":1}},"a5d0a7c1c76a40448c74fa363351aee4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_429baacd828f416088746cab16170191","placeholder":"​","style":"IPY_MODEL_aa8aad53050e44b7a605d54339cbc28b","value":" 1/1 [00:00&lt;00:00,  2.09it/s]"}},"c131155f97b14a73b35dd538b717f548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b0e01b6b61894023961db665943f2099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04aba4e93de7481798a77ec61bac428f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9e5e552a396463b9a8e6b576b2273fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6ef02c4ae245bf9a8599b7b329f11e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"429baacd828f416088746cab16170191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa8aad53050e44b7a605d54339cbc28b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e50cbadcd90c4bb68e3fbffd32dd688b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bda57594c4de408e8970754d296383d1","IPY_MODEL_eec78e000d6a48b3ae75cacba6e550ad","IPY_MODEL_b0cdd171e7474d1ab8dd7e0f08c04d3a"],"layout":"IPY_MODEL_92ed62b4600e44e898e2795c33dcfda2"}},"bda57594c4de408e8970754d296383d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd4073e5c0994003ab40b2ec70540f09","placeholder":"​","style":"IPY_MODEL_a07b176d12f44f19afc057900bf25cb9","value":"Epoch 0:   0%"}},"eec78e000d6a48b3ae75cacba6e550ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_68e76d2671e04209b295da4db6920ce8","max":31,"min":0,"orientation":"horizontal","style":"IPY_MODEL_021e28fe45044b7c965020d78bccf4f7","value":0}},"b0cdd171e7474d1ab8dd7e0f08c04d3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f00359f1c9cc465a897c39bfde587a3d","placeholder":"​","style":"IPY_MODEL_04c99bbfdbc440e4aa3dbeb99fed41dc","value":" 0/31 [00:00&lt;?, ?it/s]"}},"92ed62b4600e44e898e2795c33dcfda2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cd4073e5c0994003ab40b2ec70540f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a07b176d12f44f19afc057900bf25cb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e76d2671e04209b295da4db6920ce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"021e28fe45044b7c965020d78bccf4f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f00359f1c9cc465a897c39bfde587a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c99bbfdbc440e4aa3dbeb99fed41dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6HN4S9vaiWLi","executionInfo":{"status":"ok","timestamp":1653279790804,"user_tz":240,"elapsed":19596,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"30371f8a-8f19-4046-ce53-057f31a87341"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","from os.path import join\n","import os\n","\n","ROOT = '/content/drive'     # default for the drive\n","PROJ = 'My Drive/Colab Notebooks/'       # path to your project on Drive\n","\n","\n","\n","drive.mount(ROOT)           # we mount the drive at /content/drive\n","\n","PROJECT_PATH = join(ROOT, PROJ)\n"]},{"cell_type":"code","source":["GIT_USERNAME = \"ahhuang007\" # replace with yours\n","GIT_TOKEN = os.environ['git_key_wsb']           # definitely replace with yours\n","GIT_REPOSITORY = \"wallstreetbets\"      # ...nah\n"],"metadata":{"id":"snIdnvv-wJ7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir \"{PROJECT_PATH}\"    # in case we haven't created it already   \n","%cd \"{PROJECT_PATH}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XqYEi6upis0","executionInfo":{"status":"ok","timestamp":1647516809796,"user_tz":240,"elapsed":403,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"73d82c72-f75b-479e-8340-26365b00c322"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/drive/My Drive/Colab Notebooks/wallstreetbets’: File exists\n","/content/drive/My Drive/Colab Notebooks/wallstreetbets\n"]}]},{"cell_type":"code","source":["#GIT_PATH = \"https://GIT_TOKEN@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\"\n","!git clone \"https://$git_key_wsb@github.com/ahhuang007/wallstreetbets.git\"\n","#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMTfkjNSpuYe","executionInfo":{"status":"ok","timestamp":1647517803697,"user_tz":240,"elapsed":2394,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"187e83e5-6614-4bc4-8f97-6800ea9c7509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'wallstreetbets'...\n","remote: Enumerating objects: 362, done.\u001b[K\n","remote: Counting objects: 100% (362/362), done.\u001b[K\n","remote: Compressing objects: 100% (225/225), done.\u001b[K\n","remote: Total 362 (delta 202), reused 293 (delta 133), pack-reused 0\u001b[K\n","Receiving objects: 100% (362/362), 3.16 MiB | 10.17 MiB/s, done.\n","Resolving deltas: 100% (202/202), done.\n"]}]},{"cell_type":"code","source":["%cd wallstreetbets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I59ruptYtuE4","executionInfo":{"status":"ok","timestamp":1648396085927,"user_tz":240,"elapsed":227,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"2855ee80-1cf5-4324-b68e-ded181a51cf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'wallstreetbets'\n","/content\n"]}]},{"cell_type":"code","source":["!mv ./wallstreetbets/* \"{PROJECT_PATH}\""],"metadata":{"id":"p-XYNmsIpvsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf ./wallstreetbets"],"metadata":{"id":"ZP4q1VFMqNC-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pulling data from Github"],"metadata":{"id":"90LEBMUWGvEc"}},{"cell_type":"code","source":["%cd drive/My Drive/Colab Notebooks/wallstreetbets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KuOaDyRdEG_a","executionInfo":{"status":"ok","timestamp":1651718361261,"user_tz":240,"elapsed":147,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"31f279ab-addc-40ae-86e9-39dc5844b330"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/wallstreetbets\n"]}]},{"cell_type":"code","source":["!git pull origin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IW-awovGwoE","executionInfo":{"status":"ok","timestamp":1651442847044,"user_tz":240,"elapsed":39147,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"00eb54a8-58f2-4dc9-d7e1-19770cfa41c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 59, done.\u001b[K\n","remote: Counting objects:   1% (1/59)\u001b[K\rremote: Counting objects:   3% (2/59)\u001b[K\rremote: Counting objects:   5% (3/59)\u001b[K\rremote: Counting objects:   6% (4/59)\u001b[K\rremote: Counting objects:   8% (5/59)\u001b[K\rremote: Counting objects:  10% (6/59)\u001b[K\rremote: Counting objects:  11% (7/59)\u001b[K\rremote: Counting objects:  13% (8/59)\u001b[K\rremote: Counting objects:  15% (9/59)\u001b[K\rremote: Counting objects:  16% (10/59)\u001b[K\rremote: Counting objects:  18% (11/59)\u001b[K\rremote: Counting objects:  20% (12/59)\u001b[K\rremote: Counting objects:  22% (13/59)\u001b[K\rremote: Counting objects:  23% (14/59)\u001b[K\rremote: Counting objects:  25% (15/59)\u001b[K\rremote: Counting objects:  27% (16/59)\u001b[K\rremote: Counting objects:  28% (17/59)\u001b[K\rremote: Counting objects:  30% (18/59)\u001b[K\rremote: Counting objects:  32% (19/59)\u001b[K\rremote: Counting objects:  33% (20/59)\u001b[K\rremote: Counting objects:  35% (21/59)\u001b[K\rremote: Counting objects:  37% (22/59)\u001b[K\rremote: Counting objects:  38% (23/59)\u001b[K\rremote: Counting objects:  40% (24/59)\u001b[K\rremote: Counting objects:  42% (25/59)\u001b[K\rremote: Counting objects:  44% (26/59)\u001b[K\rremote: Counting objects:  45% (27/59)\u001b[K\rremote: Counting objects:  47% (28/59)\u001b[K\rremote: Counting objects:  49% (29/59)\u001b[K\rremote: Counting objects:  50% (30/59)\u001b[K\rremote: Counting objects:  52% (31/59)\u001b[K\rremote: Counting objects:  54% (32/59)\u001b[K\rremote: Counting objects:  55% (33/59)\u001b[K\rremote: Counting objects:  57% (34/59)\u001b[K\rremote: Counting objects:  59% (35/59)\u001b[K\rremote: Counting objects:  61% (36/59)\u001b[K\rremote: Counting objects:  62% (37/59)\u001b[K\rremote: Counting objects:  64% (38/59)\u001b[K\rremote: Counting objects:  66% (39/59)\u001b[K\rremote: Counting objects:  67% (40/59)\u001b[K\rremote: Counting objects:  69% (41/59)\u001b[K\rremote: Counting objects:  71% (42/59)\u001b[K\rremote: Counting objects:  72% (43/59)\u001b[K\rremote: Counting objects:  74% (44/59)\u001b[K\rremote: Counting objects:  76% (45/59)\u001b[K\rremote: Counting objects:  77% (46/59)\u001b[K\rremote: Counting objects:  79% (47/59)\u001b[K\rremote: Counting objects:  81% (48/59)\u001b[K\rremote: Counting objects:  83% (49/59)\u001b[K\rremote: Counting objects:  84% (50/59)\u001b[K\rremote: Counting objects:  86% (51/59)\u001b[K\rremote: Counting objects:  88% (52/59)\u001b[K\rremote: Counting objects:  89% (53/59)\u001b[K\rremote: Counting objects:  91% (54/59)\u001b[K\rremote: Counting objects:  93% (55/59)\u001b[K\rremote: Counting objects:  94% (56/59)\u001b[K\rremote: Counting objects:  96% (57/59)\u001b[K\rremote: Counting objects:  98% (58/59)\u001b[K\rremote: Counting objects: 100% (59/59)\u001b[K\rremote: Counting objects: 100% (59/59), done.\u001b[K\n","remote: Compressing objects: 100% (19/19), done.\u001b[K\n","remote: Total 47 (delta 31), reused 44 (delta 28), pack-reused 0\u001b[K\n","Unpacking objects: 100% (47/47), done.\n","From https://github.com/ahhuang007/wallstreetbets\n","   5db0c2d..0969224  main       -> origin/main\n","Updating 5db0c2d..0969224\n","Fast-forward\n"," .../gym_wsb/envs/__pycache__/val_env.cpython-37.pyc   | Bin \u001b[31m7979\u001b[m -> \u001b[32m8420\u001b[m bytes\n"," .../gym_wsb/envs/__pycache__/wsb_env.cpython-37.pyc   | Bin \u001b[31m8095\u001b[m -> \u001b[32m8723\u001b[m bytes\n"," gym-wsb/gym_wsb/envs/val_env.py                       |   3 \u001b[32m+++\u001b[m\n"," gym-wsb/gym_wsb/envs/wsb_env.py                       |  17 \u001b[32m++++++++++++\u001b[m\u001b[31m-----\u001b[m\n"," main.py                                               |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," models/trained_models/trained_model_ppo_v43.zip       | Bin \u001b[31m0\u001b[m -> \u001b[32m140328\u001b[m bytes\n"," models/trained_models/trained_model_ppo_v44.zip       | Bin \u001b[31m0\u001b[m -> \u001b[32m142516\u001b[m bytes\n"," models/trained_models/trained_model_ppo_v45.zip       | Bin \u001b[31m0\u001b[m -> \u001b[32m142544\u001b[m bytes\n"," models/trained_models/trained_model_ppo_v46.zip       | Bin \u001b[31m0\u001b[m -> \u001b[32m142528\u001b[m bytes\n"," validation.py                                         |   6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n"," 10 files changed, 19 insertions(+), 9 deletions(-)\n"," create mode 100644 models/trained_models/trained_model_ppo_v43.zip\n"," create mode 100644 models/trained_models/trained_model_ppo_v44.zip\n"," create mode 100644 models/trained_models/trained_model_ppo_v45.zip\n"," create mode 100644 models/trained_models/trained_model_ppo_v46.zip\n"]}]},{"cell_type":"markdown","source":["Adding stuff to Github"],"metadata":{"id":"4f3gMfIiqgwb"}},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"RhLlRgw0qQ1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"ahhuang007@gmail.com\"\n","!git config --global user.name \"ahhuang007\""],"metadata":{"id":"N9x2mPt9sghE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"gotten most of the way to getting a forecasting network up and running\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H98UYK-dsgj7","executionInfo":{"status":"ok","timestamp":1651720065176,"user_tz":240,"elapsed":1469,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"28e7dd77-04fd-4c59-bc22-5e81970882a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 0d7c13d] gotten most of the way to getting a forecasting network up and running\n"," 4 files changed, 602 insertions(+), 2 deletions(-)\n"," rewrite colab_ml_testing.ipynb (93%)\n"," rewrite colab_wsb.ipynb (97%)\n"," create mode 100644 lightning_logs/lightning_logs/version_0/events.out.tfevents.1651719883.4e271929e752.60.0\n"," create mode 100644 lightning_logs/lightning_logs/version_0/hparams.yaml\n"]}]},{"cell_type":"code","source":["!git remote set-url origin https://$git_key_wsb@github.com/ahhuang007/wallstreetbets.git"],"metadata":{"id":"UGc0gP1dsgm7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push origin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGmkPNogsgqe","executionInfo":{"status":"ok","timestamp":1651720072385,"user_tz":240,"elapsed":3952,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"d093d0b0-a8ee-4861-b3ae-a3dcce270801"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counting objects: 1   \rCounting objects: 9, done.\n","Delta compression using up to 2 threads.\n","Compressing objects:  14% (1/7)   \rCompressing objects:  28% (2/7)   \rCompressing objects:  42% (3/7)   \rCompressing objects:  57% (4/7)   \rCompressing objects:  71% (5/7)   \rCompressing objects:  85% (6/7)   \rCompressing objects: 100% (7/7)   \rCompressing objects: 100% (7/7), done.\n","Writing objects:  11% (1/9)   \rWriting objects:  22% (2/9)   \rWriting objects:  33% (3/9)   \rWriting objects:  44% (4/9)   \rWriting objects:  55% (5/9)   \rWriting objects:  66% (6/9)   \rWriting objects:  77% (7/9)   \rWriting objects:  88% (8/9)   \rWriting objects: 100% (9/9)   \rWriting objects: 100% (9/9), 83.06 KiB | 5.54 MiB/s, done.\n","Total 9 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/ahhuang007/wallstreetbets.git\n","   0969224..0d7c13d  main -> main\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lza962RtBtP","executionInfo":{"status":"ok","timestamp":1647518083454,"user_tz":240,"elapsed":380,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"2dae47eb-a5a1-4791-c5c3-fc773abde689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   colab_wsb.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"markdown","source":["Actual Code Below"],"metadata":{"id":"mYDhBBk4u_ap"}},{"cell_type":"markdown","source":["The reason for this Colab file is to explore the viability of using a NN instead of an RL policy - in theory, we already know a basic optimal policy (buy before it increases, sell before it decreases), we just need to figure out if it will increase/decrease beforehand, which a NN can maybe do."],"metadata":{"id":"AtrAp9UBvBzE"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"W_U12lMbvhe4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd drive/MyDrive/Colab Notebooks/wallstreetbets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Xd5Zi1ZvlQY","executionInfo":{"status":"ok","timestamp":1651719617916,"user_tz":240,"elapsed":196,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"8b2ff773-158a-492a-a18c-d9521d91cf3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/wallstreetbets\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import torch\n","import numpy as np\n","\n","class wsb_dataset(Dataset):\n","  \"\"\"class for formatting training data\"\"\"\n","\n","  def __init__(self, df, labels):\n","    self.df = df\n","    self.labels = labels\n","  \n","  def __len__(self):\n","    return len(self.df)\n","  \n","  def __getitem__(self, idx):\n","    sample = self.df.iloc[idx, :]\n","    sample = np.array([sample])\n","    sample = sample.astype('float')#.reshape(-1, 2)\n","    label = self.labels[idx]\n","    return sample, label"],"metadata":{"id":"32vAkRXZc3qZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Gathering data, formatting it for NN\n","from sklearn.preprocessing import MinMaxScaler\n","\n","dfs = []\n","training_datas = []\n","cryptos = ['AAVE', 'ADA', 'ALGO', 'ATOM', \n","           'AVAX', 'BCH', 'BTC', 'DOT', \n","           'ETH', 'LINK', 'LRC', 'LTC', \n","           'MANA', 'MATIC', 'SOL', 'UNI']\n","cryptos = ['BTC']\n","for c in cryptos:\n","    df = pd.read_csv('./data/' + c + '_data.csv')\n","    '''I think we'll do a similar plan to my source idea.\n","    5 months for training, 2 months for validation/tuning, 5 months for testing\n","    '''\n","    #dfs.append(df[38:175200].reset_index(drop = True))\n","    #Splitting data into training/validation/test\n","    \n","    df = df.drop(['timestamp', 'Unnamed: 0'], axis = 1)\n","    df = df[38:]\n","\n","    #Normalizing data\n","    scaler = MinMaxScaler()\n","    df = pd.DataFrame(data = scaler.fit_transform(df))\n","    labels = df[3][1:].reset_index(drop = True)\n","    training = wsb_dataset(df[:175200].reset_index(drop = True), labels[:175200].reset_index(drop = True))\n","    validation = wsb_dataset(df[175200:282600].reset_index(drop = True), labels[175200:282600].reset_index(drop = True))\n","    testing = wsb_dataset(df[262800:-1].reset_index(drop = True), labels[262800:].reset_index(drop = True))\n","    training_datas.append([training, validation, testing])"],"metadata":{"id":"8ngaHFFmu-i0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(training_datas[0][0], batch_size = 64)\n","valid_dataloader = DataLoader(training_datas[0][1], batch_size = 64)"],"metadata":{"id":"1Qa9FtynyPZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for X, y in train_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-TmdDr7zxyh","executionInfo":{"status":"ok","timestamp":1648401035786,"user_tz":240,"elapsed":431,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"a839af9c-a8f3-4eec-e6f2-381716f5cb00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 8])\n","Shape of y: torch.Size([64]) torch.float64\n"]}]},{"cell_type":"code","source":["##Create NN\n","from torch import nn\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(8, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        #print(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n"],"metadata":{"id":"KFszVDG471Ah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"id":"u-6CjdVTaaZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weighted_mse_loss(input, target, weight):\n","    return torch.sum(weight * (input - target) ** 2)"],"metadata":{"id":"4lLScmeoCg7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"],"metadata":{"id":"1-qKDl95b4gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Train NN\n","import time\n","def train(dataloader, model, loss_fn, optimizer, accs):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X.float())\n","        loss = loss_fn(pred.squeeze(), y.float())\n","        #print(pred)\n","        #print(loss)\n","        #time.sleep(10)\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 1000 == 0:\n","            #print(loss)\n","            loss, current = loss.item(), batch * len(X)\n","            \n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","            accs.append(loss)\n","    return accs"],"metadata":{"id":"IF0N43R0-MEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for X, y in train_dataloader:\n","  print(X[0])\n","  preds = model(X.float())\n","  print(preds)\n","  print(loss_fn(preds.squeeze(), y.float()))\n","  break"],"metadata":{"id":"iyBu8yrPZU6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(dataloader, model, loss_fn, accs):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X.float())\n","            test_loss += loss_fn(pred.squeeze(), y.float()).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    accs.append(test_loss)\n","    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n","    return accs"],"metadata":{"id":"N3WEKx1Wb_Z0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accs = []\n","test_accs = []"],"metadata":{"id":"ScyCrHnIExb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 15\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    if t < 2:\n","        train_accs = train(train_dataloader, model, loss_fn, optimizer, train_accs)\n","        test_accs = test(valid_dataloader, model, loss_fn, test_accs)\n","    elif t >= 2 and test_accs[-1] < test_accs[-2]:\n","        train_accs = train(train_dataloader, model, loss_fn, optimizer, train_accs)\n","        test_accs = test(valid_dataloader, model, loss_fn, test_accs)\n","    else:\n","        pass\n","print(\"Done!\")"],"metadata":{"id":"jiOsTxGccDdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from os import listdir\n","from os.path import isfile, join\n","\n","onlyfiles = [f for f in listdir('./nn_stuff/models') \n","             if isfile(join('./nn_stuff/models', f))]\n","version = str(len(onlyfiles))\n","\n","torch.save(model.state_dict(), \"nn_stuff/models/model_\" + version + \".pth\")"],"metadata":{"id":"Knra9cgBAY0e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting data (pretty much just losses)"],"metadata":{"id":"IGY7chhEC8EP"}},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","fig = plt.figure()\n","plt.plot(train_accs)\n","plt.show()"],"metadata":{"id":"Vw3YRAjvCIXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure()\n","plt.plot(test_accs)\n","plt.show()"],"metadata":{"id":"2es34BdmC0pV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Test model in testing data\n","\n","#basic framework - for each timestep, we feed data into network to get prediction.\n","#If price will increase by enough, we buy/hold. If it will decrease, we sell/don't buy.\n","\n","#Code for loading saved model\n","model = NeuralNetwork()\n","model.load_state_dict(torch.load(\"nn_stuff/models/model_4.pth\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMxUoUsnAmaI","executionInfo":{"status":"ok","timestamp":1648401062930,"user_tz":240,"elapsed":113,"user":{"displayName":"Andy Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11605925934433602638"}},"outputId":"f875ef7e-8229-410d-c230-79261f812c52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["testing_loader = DataLoader(training_datas[0][2], batch_size = 1)"],"metadata":{"id":"-n42fCrLgkxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for X, y in testing_loader:\n","  print(X)\n","  print(X[0])\n","  preds = model(X.float())\n","  print(preds)\n","  print(loss_fn(preds.squeeze(), y.float()))\n","  break"],"metadata":{"id":"D-APiYgdgtNB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DCA approach - use max(10% of balance, $10) to buy, 10% of shares to sell\n","def sell_low(balance, shares, close):\n","    if shares > 0:\n","        #update balance\n","        amount = \n","        balance += amount * close\n","        shares -= amount\n","    else:\n","        pass #No shares to sell!\n","    return balance, shares\n","\n","def buy_high(balance, shares, close):\n","    if balance > 0:\n","        #update balance\n","        amount = max(0.1 * balance, 10)\n","        amount = min(balance, amount)\n","        shares += (amount / close)\n","        balance -= amount\n","        \n","    else:\n","        pass #No money to buy!\n","    return balance, shares"],"metadata":{"id":"kADT1skQXHct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#naive approach - all-in trades with no fees\n","def sell_low(balance, shares, close):\n","    if shares > 0:\n","        #update balance\n","        balance += shares * close\n","        shares = 0\n","    else:\n","        pass #No shares to sell!\n","    return balance, shares\n","\n","def buy_high(balance, shares, close):\n","    if balance > 0:\n","        #update balance\n","        shares += (balance / close)\n","        balance = 0\n","        \n","    else:\n","        pass\n","    return balance, shares"],"metadata":{"id":"7bS5gDRtmkf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["balance = 100\n","shares = 0\n","counter = 262800\n","orig_df = pd.read_csv('./data/BTC_data.csv')[262799:]\n","total = []\n","cur = orig_df.loc[262799, \"close\"]\n","for X, y in testing_loader:\n","    if counter % 10000 == 0:\n","        print(\"Timestep {}: Balance is {}, shares is {}, total is {}\".format(counter, balance, shares, total[-1]))\n","    pred = model(X.float()).item()\n","    cur_norm = X[0][0][3].item()\n","    #Figuring out which action to take\n","    if pred > cur_norm:\n","        balance, shares = buy_high(balance, shares, cur)\n","        #print(\"buying\")\n","    elif pred < cur_norm:\n","        balance, shares = sell_low(balance, shares, cur)\n","        #print(\"selling\")\n","    #time.sleep(3)\n","    total.append(balance + shares * cur)\n","    #Updating for next step\n","    counter += 1\n","    cur = orig_df.loc[counter, \"close\"]"],"metadata":{"id":"MIbktgkJjZUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig = plt.figure()\n","plt.plot(total)\n","plt.show()"],"metadata":{"id":"huydIs_HU_Kj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Downloading file\n","from google.colab import files\n","\n","with open('example.txt', 'w') as f:\n","  f.write('some content')\n","\n","files.download('example.txt')"],"metadata":{"id":"26DjLR6R4Dqo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So the traditional NN didn't pan out - will try using time series forecasting instead to see results"],"metadata":{"id":"uLiUeEP1qqjl"}},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"id":"vXnUfAVQrLeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_forecasting"],"metadata":{"id":"noNzkPOnrYHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import copy\n","from pathlib import Path\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import TensorBoardLogger\n","import torch\n","\n","from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n","from pytorch_forecasting.data import GroupNormalizer\n","from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n","from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n","#Various imports"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qywjGmW0q3Xm","executionInfo":{"status":"ok","timestamp":1651719699002,"user_tz":240,"elapsed":14055,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"018aa965-aa5b-4451-a5a2-a23324fd3b21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('./data/BTC_data.csv')\n","'''I think we'll do a similar plan to my source idea.\n","5 months for training, 2 months for validation/tuning, 5 months for testing\n","'''\n","#dfs.append(df[38:175200].reset_index(drop = True))\n","#Splitting data into training/validation/test\n","\n","df = df.drop(['Unnamed: 0'], axis = 1)\n","df[\"time_idx\"] = [int(x/60) for x in df[\"timestamp\"]] \n","df[\"crypto\"] = \"BTC\"\n","\n","#Apparently I have some missing timestamps, which is super weird"],"metadata":{"id":"kA58FDNIuliW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_prediction_length = 6\n","max_encoder_length = 24\n","training_cutoff = df[\"time_idx\"].max() - max_prediction_length\n","\n","training = TimeSeriesDataSet(\n","    df[lambda x: x.time_idx <= training_cutoff],\n","    time_idx=\"time_idx\",\n","    target=\"close\",\n","    group_ids=[\"crypto\"],\n","    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n","    max_encoder_length=max_encoder_length,\n","    min_prediction_length=1,\n","    max_prediction_length=max_prediction_length,\n","    time_varying_known_categoricals=[\"crypto\"],\n","    time_varying_known_reals=[\"time_idx\"],\n","    time_varying_unknown_categoricals=[],\n","    time_varying_unknown_reals=[\n","        \"open\",\n","        \"high\",\n","        \"low\",\n","        \"close\",\n","        \"volume\",\n","        \"MACD\",\n","        \"CCI\",\n","        \"ADX\",\n","        \"RSI\"\n","    ],\n","    target_normalizer=GroupNormalizer(\n","        groups=[\"crypto\"], transformation=\"softplus\"\n","    ),  # use softplus and normalize by group\n","    add_relative_time_idx=True,\n","    add_target_scales=True,\n","    add_encoder_length=True,\n","    allow_missing_timesteps = True\n",")\n","\n","# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n","# for each series\n","validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n","\n","# create dataloaders for model\n","batch_size = 128  # set this between 32 to 128\n","train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n","val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"],"metadata":{"id":"FY0DIgGAEoKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n","actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n","baseline_predictions = Baseline().predict(val_dataloader)\n","(actuals - baseline_predictions).abs().mean().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"el0NPj6Wf8bX","executionInfo":{"status":"ok","timestamp":1651719718655,"user_tz":240,"elapsed":367,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"895a5820-4ca1-4979-827a-ed8c5d55326c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"]},{"output_type":"execute_result","data":{"text/plain":["27.580078125"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n","#This broke pytorch_lightning before, beware!"],"metadata":{"id":"1aRFfcKUJRuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configure network and trainer\n","pl.seed_everything(4)\n","trainer = pl.Trainer(\n","    gpus=0,\n","    # clipping gradients is a hyperparameter and important to prevent divergance\n","    # of the gradient for recurrent neural networks\n","    gradient_clip_val=0.1,\n","    log_every_n_steps = 25\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7RDMLvVgAfi","executionInfo":{"status":"ok","timestamp":1651719732025,"user_tz":240,"elapsed":375,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"3d61dd14-d602-4430-e483-a866d5ee4280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 4\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n","  category=PossibleUserWarning,\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["tft = TemporalFusionTransformer.from_dataset(\n","    training,\n","    # not meaningful for finding the learning rate but otherwise very important\n","    learning_rate=0.03,\n","    hidden_size=16,  # most important hyperparameter apart from learning rate\n","    # number of attention heads. Set to up to 4 for large datasets\n","    attention_head_size=1,\n","    dropout=0.1,  # between 0.1 and 0.3 are good values\n","    hidden_continuous_size=8,  # set to <= hidden_size\n","    output_size=7,  # 7 quantiles by default\n","    loss=QuantileLoss(),\n","    # reduce learning rate if no improvement in validation loss after x epochs\n","    reduce_on_plateau_patience=4,\n",")\n","print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMoaMkVr7VRf","executionInfo":{"status":"ok","timestamp":1651719737419,"user_tz":240,"elapsed":348,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"c8b717dd-03d5-4bf4-d0d5-fbb925987994"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters in network: 24.8k\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"]}]},{"cell_type":"code","source":["# find optimal learning rate\n","res = trainer.tuner.lr_find(\n","    tft,\n","    train_dataloaders=train_dataloader,\n","    val_dataloaders=val_dataloader,\n","    max_lr=10.0,\n","    min_lr=1e-6,\n",")\n","\n","print(f\"suggested learning rate: {res.suggestion()}\")\n","fig = res.plot(show=True, suggest=True)\n","fig.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408,"referenced_widgets":["ba1d7dfc4526444b8dd9b528bbd72ab1","33ace3c171d649268e07e51e000213c0","47b802f304e0422ca87ed99774c14bc9","494786c15e714fb890c529a251ab49f6","25d7a43716014360b4d7136b2bc179bb","8834dfcf6c134a1989be21a3fbb06d95","97b6e8f2b84343c69b7baf1d7f2aa7e9","5c5078b1184c44babea57188016651c7","a448c5c29ae24583b07be9d1abc4170c","30cf8fbff230435d99737abe196b7ca5","72696459bf9d4ee9a95b734bf0a170ff"]},"id":"svIeYpJt7ZWZ","executionInfo":{"status":"ok","timestamp":1651719778554,"user_tz":240,"elapsed":34208,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"3bbd8c4d-0dad-45d7-8ba8-37dbe4961aa9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1d7dfc4526444b8dd9b528bbd72ab1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/wallstreetbets/.lr_find_e10efe23-11ed-4e82-af6a-886814ee9311.ckpt\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1719: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}\"].\n","  \"Be aware that when using `ckpt_path`,\"\n"]},{"output_type":"stream","name":"stdout","text":["suggested learning rate: 0.15135612484362077\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# configure network and trainer\n","early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n","lr_logger = LearningRateMonitor()  # log the learning rate\n","logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n","\n","trainer = pl.Trainer(\n","    max_epochs=30,\n","    gpus=0,\n","    weights_summary=\"top\",\n","    gradient_clip_val=0.1,\n","    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n","    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n","    callbacks=[lr_logger, early_stop_callback],\n","    logger=logger,\n",")\n","\n","\n","tft = TemporalFusionTransformer.from_dataset(\n","    training,\n","    learning_rate=0.03,\n","    hidden_size=16,\n","    attention_head_size=1,\n","    dropout=0.1,\n","    hidden_continuous_size=8,\n","    output_size=7,  # 7 quantiles by default\n","    loss=QuantileLoss(),\n","    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n","    reduce_on_plateau_patience=4,\n",")\n","print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"63KJ5CE7LIk1","executionInfo":{"status":"ok","timestamp":1651719862781,"user_tz":240,"elapsed":706,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"5b5c8288-61ee-4e8b-be5b-acc98e6b31c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["Number of parameters in network: 24.8k\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"]}]},{"cell_type":"code","source":["# fit network\n","trainer.fit(\n","    tft,\n","    train_dataloaders=train_dataloader,\n","    val_dataloaders=val_dataloader,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":971,"referenced_widgets":["1fcf19686218495dbcf90457e0dd6818","afd531712de6430e8eb4a8e0a2c73a7c","9dd123c3490d4dd290cbb3552dd69d28","a5d0a7c1c76a40448c74fa363351aee4","c131155f97b14a73b35dd538b717f548","b0e01b6b61894023961db665943f2099","04aba4e93de7481798a77ec61bac428f","c9e5e552a396463b9a8e6b576b2273fc","df6ef02c4ae245bf9a8599b7b329f11e","429baacd828f416088746cab16170191","aa8aad53050e44b7a605d54339cbc28b","e50cbadcd90c4bb68e3fbffd32dd688b","bda57594c4de408e8970754d296383d1","eec78e000d6a48b3ae75cacba6e550ad","b0cdd171e7474d1ab8dd7e0f08c04d3a","92ed62b4600e44e898e2795c33dcfda2","cd4073e5c0994003ab40b2ec70540f09","a07b176d12f44f19afc057900bf25cb9","68e76d2671e04209b295da4db6920ce8","021e28fe45044b7c965020d78bccf4f7","f00359f1c9cc465a897c39bfde587a3d","04c99bbfdbc440e4aa3dbeb99fed41dc"]},"id":"gjojJGMjLRC6","executionInfo":{"status":"error","timestamp":1651719882710,"user_tz":240,"elapsed":2804,"user":{"displayName":"Andy Huang","userId":"11605925934433602638"}},"outputId":"e6ff3823-2cf7-4d9e-e691-38a53aed56f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Missing logger folder: lightning_logs/lightning_logs\n","\n","   | Name                               | Type                            | Params\n","----------------------------------------------------------------------------------------\n","0  | loss                               | QuantileLoss                    | 0     \n","1  | logging_metrics                    | ModuleList                      | 0     \n","2  | input_embeddings                   | MultiEmbedding                  | 1     \n","3  | prescalers                         | ModuleDict                      | 224   \n","4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K \n","5  | encoder_variable_selection         | VariableSelectionNetwork        | 7.7 K \n","6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.3 K \n","7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n","8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n","9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n","10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n","11 | lstm_encoder                       | LSTM                            | 2.2 K \n","12 | lstm_decoder                       | LSTM                            | 2.2 K \n","13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n","14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n","15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n","16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n","17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n","18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n","19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n","20 | output_layer                       | Linear                          | 119   \n","----------------------------------------------------------------------------------------\n","24.8 K    Trainable params\n","0         Non-trainable params\n","24.8 K    Total params\n","0.099     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fcf19686218495dbcf90457e0dd6818"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  category=PossibleUserWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e50cbadcd90c4bb68e3fbffd32dd688b"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-0b3f9c96239d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         )\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         )\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         )\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPUAccelerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \"\"\"\n\u001b[0;32m-> 1644\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_track_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/optim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreevaluates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# note - below is commented out b/c I have other work that passes back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mconsistent\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msubclasses\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# manually capture logged metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/models/base_model.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\u001b[0m in \u001b[0;36mcreate_log\u001b[0;34m(self, x, y, out, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"interpretation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_interpretation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\u001b[0m in \u001b[0;36m_log_interpretation\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mattention_prediction_horizon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# attention only for first prediction horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         )\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\u001b[0m in \u001b[0;36minterpret_output\u001b[0;34m(self, out, reduction, attention_prediction_horizon)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;31m# histogram of decode and encode lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mencoder_length_histogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_encoder_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         decoder_length_histogram = integer_histogram(\n\u001b[1;32m    630\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoder_lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoder_variables\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_forecasting/utils.py\u001b[0m in \u001b[0;36minteger_histogram\u001b[0;34m(data, min, max)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     hist = torch.zeros(max - min + 1, dtype=torch.long, device=data.device).scatter(\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muniques\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: index 52 is out of bounds for dimension 0 with size 25"]}]}]}